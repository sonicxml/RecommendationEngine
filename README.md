# Recommendation Engine
Graph Toolkit and Recommendation Engine for a NETS 150 homework assignment.

Built in the spring of Freshman Year (Spring '15) by UPenn students Trevin Gandhi, Seth Bartynski, and Deepan Saravanan. 

Our goal for this project was to develop a graph toolkit and recommendation engine. The underlying core of our project was based on a graph representation that consisted of a Graph class wrapped around Node and Edge instances. This representation could be built from reading in .txt files, as can be seen in the DataReader class. For the rest of the project, we focused on implementing two external APIs.

The first API was the GraphToolkit class. This toolkit contains a variety of graph algorithms that an end-user may want to run. The full list is: BFS, DFS, Topological Sort, Kosaraju’s, Bellman-Ford Single Source Shortest Path, Floyd-Warshall All Pairs Shortest Path, Ford-Fulkerson Max Flow, Brandes’ Betweenness Centrality, and Dampened PageRank (using linear algebra).

The second API was the Recommender class. This class operates on bipartite graphs in which one set of nodes represents people and the other represents items of some sort. The edges are directed from people to items and the edge weights typically represent the person’s rating of that item. Our Recommender class uses a collaboration filter, which uses similarity metrics to find the most similar users to the input user (which we will call i). The two similarity metrics we implemented are the Pearson Correlation Coefficient and the Jaccard Similarity Coefficient. The Pearson Correlation Coefficient is a measure that takes two users and returns their covariance divided by the product of their standard deviations. This value will always be in the range [-1, 1], where 1 implies that there is complete correlation between the two users, while -1 implies there is a complete negative correlation. For the Jaccard Similarity Coefficient, let us define A to be the set of items user 1 has rated and B to be the set of items user 2 has rated. The Jaccard Similarity Coefficient then is A∩BA∪B.

Once we had a set of scores for all the other users, we sorted and chose the top k of those, where k was a parameter to the function. Our previous metric summed up the values for the items that were adjacent to the k most similar users and returned those items with the highest score.  However, this was not a fair representation of the rating system, and was thus inaccurate.  For example, if all k users give a movie a rating of 2 out of 5, then that movie will have score 2k, a relatively high score, even though it was not really recommended by the similar users.  Thus, we changed the metric to be the total weight of the ratings divided by the square root of the number of users who rated that item.  This metric is more robust, and gives more of a weighted average.  It also favors items that were rated by multiple users, to avoid the problem of a single 5 out of 5 rating being the best recommendation returned. 
